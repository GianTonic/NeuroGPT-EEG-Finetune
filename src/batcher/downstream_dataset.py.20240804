import os
import mne
import numpy as np
from batcher.base import EEGDataset
from scipy.io import loadmat
from scipy.signal import butter, filtfilt

class MotorImageryDataset(EEGDataset):
    def __init__(self, filenames, sample_keys, chunk_len=500, num_chunks=10, ovlp=50, root_path="", gpt_only=True):
        super().__init__(filenames, sample_keys, chunk_len, num_chunks, ovlp, root_path=root_path, gpt_only=gpt_only)

        self.data_all = []
        for fn in self.filenames:
            if fn.endswith('.gdf'):
                print(f"Loading GDF file: {fn}")
                raw = mne.io.read_raw_gdf(fn, preload=True)
                data, times = raw[:]
                self.data_all.append({
                    's': data,
                    'etyp': raw.annotations.description,
                    'epos': raw.annotations.onset * raw.info['sfreq'],
                    'edur': raw.annotations.duration * raw.info['sfreq'],
                    'artifacts': np.zeros_like(raw.annotations.onset)  # Modify as needed
                })
                print(f"Loaded GDF file: {fn} with data shape {data.shape}")
                print(f"Annotations: {raw.annotations}")
            else:
                print(f"Loading NPY file: {fn}")
                self.data_all.append(np.load(fn, allow_pickle=True))
                print(f"Loaded NPY file: {fn} with data: {self.data_all[-1]}")

        self.mi_types = {769: 'left', 770: 'right', 771: 'foot', 772: 'tongue', 1023: 'rejected'}
        self.labels_string2int = {'left': 0, 'right': 1, 'foot': 2, 'tongue': 3}
        self.Fs = 250  # 250Hz from original paper
        self.P = np.load("../inputs/tMatrix_value.npy")

        self.trials, self.labels, self.num_trials_per_sub = self.get_trials_all()

    def __len__(self):
        total_len = sum(self.num_trials_per_sub)
        print(f"Dataset length: {total_len}")
        return total_len

    def __getitem__(self, idx):
        print(f"Accessing index: {idx} of {self.__len__()}")  # Debugging statement
        if idx >= len(self.trials) or idx < 0:
            raise IndexError(f"Index {idx} out of bounds for trials of size {len(self.trials)}")
        return self.preprocess_sample(self.trials[idx], self.num_chunks, self.labels[idx])


    def map2pret(self, data):
        print(f"Shape of self.P: {self.P.shape}")  # Debugging statement
        print(f"Shape of data: {data.shape}")  # Debugging statement
        # if self.P.shape[1] != data.shape[0]:
        #      print("Reshaping data to match dimensions")
        #      if self.P.shape[1] > data.shape[0]:
        #          pad_width = self.P.shape[1] - data.shape[0]
        #          data = np.pad(data, ((0, pad_width), (0, 0)), mode='constant')
        #      else:
        #          data = data[:self.P.shape[1], :]
        
        # print(f"Shape of self.P after adjustment: {self.P.shape}")  # Debugging statement
        # print(f"Shape of data after adjustment: {data.shape}")  # Debugging statement
        return np.matmul(self.P, data)  # 22x22, 22xTime

    def get_trials_from_single_subj(self, sub_id):
        raw = self.data_all[sub_id]['s'].T
        events_type = self.data_all[sub_id]['etyp']
        events_position = self.data_all[sub_id]['epos']
        events_duration = self.data_all[sub_id]['edur']
        artifacts = self.data_all[sub_id]['artifacts']

        print(f"Subject {sub_id} annotations: {events_type}")

        startrial_code = 768
        starttrial_events = events_type == str(startrial_code)
        idxs = [i for i, x in enumerate(starttrial_events) if x]
        print(f"Subject {sub_id} - Start trial events: {len(idxs)} found")

        trial_labels = self.get_labels(sub_id)

        trials = []
        classes = []
        for j, index in enumerate(idxs):
            try:
                classes.append(trial_labels[j])

                start = int(events_position[index])
                stop = start + int(events_duration[index])
                trial = raw[:22, start + 500: stop - 375]
                trials.append(trial)
                print(f"Loaded trial {j} from subject {sub_id} with shape {trial.shape}")
            except Exception as e:
                print(f"Cannot load trial {j} from subject {sub_id}: {e}")
                continue
        print(f"Total trials loaded from subject {sub_id}: {len(trials)}")
        return trials, classes

    def get_labels(self, sub_id):
        label_path = os.path.join(self.root_path, "true_labels")
        base_name = os.path.basename(self.filenames[sub_id])
        sub_name = os.path.splitext(base_name)[0]
        label_file = os.path.join(label_path, sub_name + ".mat")
        
        print(f"Looking for label file: {label_file}")  # Debugging statement

        if not os.path.exists(label_file):
            raise FileNotFoundError(f"Label file not found: {label_file}")

        labels = loadmat(label_file)["classlabel"]
        return labels.squeeze() - 1

    def get_trials_all(self):
        trials_all = []
        labels_all = []
        total_num = []
        for sub_id in range(len(self.data_all)):
            trials, labels = self.get_trials_from_single_subj(sub_id)
            total_num.append(len(trials))
            
            trials_all.append(np.array(trials))
            labels_all.append(np.array(labels))

        print(f"Total number of trials: {total_num}")
        if trials_all:
            trials_all_arr = np.vstack(trials_all)
            trials_all_arr = self.map2pret(trials_all_arr)
            print(f"Number of trials after preprocessing: {trials_all_arr.shape[0]}")
            print(f"Number of labels: {len(labels_all)}")
            return self.normalize(trials_all_arr), np.array(labels_all).flatten(), total_num
        else:
            raise ValueError("No trial data available to concatenate")

    def bandpass_filter(self, data, lowcut, highcut, fs, order=5):
        nyq = 0.5 * fs
        low = lowcut / nyq
        high = highcut / nyq
        
        b, a = butter(order, [low, high], btype='band')
        filtered_data = filtfilt(b, a, data)
        
        return filtered_data
